{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this module is to handle interactions with a database.\n",
    "\n",
    "Reading, writing, creating, deleting, connecting and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal 1: connect to google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import datetime as dt\n",
    "import regex as re\n",
    "\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG_PATH = \"../db_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timers():\n",
    "    \"\"\"A class for  Timing-stamping cell calls.\"\"\"\n",
    "    import datetime as dt\n",
    "\n",
    "    def exec_time(msg=\"Completed task\"):\n",
    "        \"\"\"\n",
    "        Runtime message tracking cell progress. Prints an message and a timestamp.\n",
    "        \n",
    "        Parameters\n",
    "        -------\n",
    "        msg (str): User provided message. Defaults to a generic statement.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            now = dt.datetime.now().strftime(\"%H:%M:%S - %Y-%m-%d\")\n",
    "            print(\n",
    "                \"{msg} Timestamp: {now}\".format(msg=msg, now=now)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Warning: unable to Run exec_time.\\nRawmessage: {msg}.\\n{error}\".format(msg=msg, error=e))\n",
    "\n",
    "\n",
    "class Google():\n",
    "    \"\"\"\"A class to connect to Google services.\"\"\"\n",
    "\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    SERVICE_ACCOUNT = None\n",
    "\n",
    "    def google_connect(self, credentials_path=None, service_account_env_var=None) -> (any, pygsheets.client.Client):\n",
    "        \"\"\"\n",
    "        Connects to google drive and spreadsheets. Requires '[...]/client_secrets[...].json\" and or \n",
    "        a service account variable in the form of a name (str).\n",
    "        Will create a token in '.' to track authentication. \n",
    "        Returns a service object to allow connections to google drive files.\n",
    "        Warning: do not share your token or anyone will have access to all content on your drive.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        credentials_path (str): Path to client secrets json.\n",
    "        service_account_env_var (str): Name of environment variable for google connection.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        gdrive (googleapiclient.discovery.Resource): Resource object with connection to google drive.\n",
    "        gsheets (pygsheets.client.Client): pygsheets client object to manipulate gsheets.\n",
    "        \"\"\"\n",
    "        \n",
    "        SCOPES = [\"https://www.googleapis.com/auth/drive\"]\n",
    "        gdrive, gsheets = None, None\n",
    "\n",
    "        if credentials_path != None: \n",
    "            creds = None \n",
    "\n",
    "            # Authentication flow.\n",
    "            if Path(\"token.pickle\").exists():\n",
    "                with open(\"token.pickle\", \"rb\") as token:\n",
    "                    creds = self.pickle.load(token)\n",
    "            if not creds or not creds.valid:\n",
    "                if creds and creds.expired and creds.refresh_token:\n",
    "                    creds.refresh(Request())\n",
    "                else:\n",
    "                    flow = InstalledAppFlow.from_client_secrets_file(credentials_path, SCOPES)\n",
    "                    creds = flow.run_local_server(port=0)\n",
    "                    # Save access token for future use.\n",
    "                    with open(\"token.pickle\", \"wb\") as token:\n",
    "                        self.pickle.dump(creds, token)\n",
    "\n",
    "            gdrive = build(\"drive\", \"v3\", credentials=creds)\n",
    "            gsheets = pygsheets.authorize(custom_credentials=creds)\n",
    "\n",
    "        elif service_account_env_var != None:\n",
    "            # dev note: not getting gdrive in this case yet.\n",
    "            gsheets = pygsheets.authorize(service_account_env_var=service_account_env_var)\n",
    "\n",
    "        return gdrive, gsheets\n",
    "    \n",
    "\n",
    "    def write_to_googlesheets(\n",
    "        self, \n",
    "        data: pd.DataFrame, \n",
    "        gsheetkey: str,\n",
    "        gsheets: pygsheets.client.Client,\n",
    "        wks_title: str, \n",
    "        row_start=\"A1\",\n",
    "        \n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Push DataFrame to Googlesheet via key.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        data (pd.DataFrame): Dataframe with data to push.\n",
    "        gsheetkey (str): Key to google sheet.\n",
    "        gsheets (pygsheets client object): Google sheets connection object.\n",
    "        data (pd.DataFrame): Dataframe with data to push.\n",
    "        wks_title (str): Worksheet title.\n",
    "        row_start (str): Set where the dataframe starting cell will write. Use A1 formatting.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        (None)\n",
    "        \"\"\"\n",
    "        df0 = data.copy(deep=True) \n",
    "\n",
    "        sh = gsheets.open_by_key(gsheetkey)\n",
    "\n",
    "        wks = sh.worksheet(\"title\", wks_title)\n",
    "        wks.clear(start=row_start, end=None)\n",
    "\n",
    "        if wks.rows < len(df0):\n",
    "            msg = \"Warning: Data rows exceeds worksheet rows available. Expanding worksheet.\"\n",
    "            # logger.warning(msg)\n",
    "            Timers.exec_time(msg)\n",
    "\n",
    "            wks.resize(rows=len(df0))\n",
    "\n",
    "        wks.set_dataframe(df0, start=row_start, copy_head=True)\n",
    "\n",
    "        log_msg = f\"Pushed data to gsheet with key:{gsheetkey}\"\n",
    "        # logger.info(log_msg)\n",
    "        Timers.exec_time(log_msg)\n",
    "\n",
    "\n",
    "class DB_handler():\n",
    "    \"\"\"\n",
    "    A class for handling my database connections.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.DB_CONFIG_PATH = \"../db_config.yaml\"\n",
    "\n",
    "\n",
    "    def _load_config(\n",
    "        self,\n",
    "        credentials_path: str, \n",
    "    ):\n",
    "        \"\"\"\n",
    "        Load configurations for database.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        credentials_path (str): Path to credentials.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ((list)): Tuple of columns.\n",
    "        \"\"\"\n",
    "        db_configs = yaml.safe_load(open(self.DB_CONFIG_PATH))\n",
    "        merge_columns = db_configs[\"column_configs\"][\"merge_columns\"]\n",
    "        fixed_columns = db_configs[\"column_configs\"][\"fixed_columns\"]\n",
    "        update_columns = db_configs[\"column_configs\"][\"update_columns\"]\n",
    "        sort_by = db_configs[\"column_configs\"].get(\"sort_by\", None)\n",
    "        return merge_columns, fixed_columns, update_columns, sort_by\n",
    "\n",
    "\n",
    "    def responses_to_df(self, data: dict) -> dict: \n",
    "        \"\"\"\n",
    "        Given a dictionary of requests.models.Response -s, \n",
    "        return a dataframe version of these responses for our database.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        data (pd.DataFrame)): DataFrame of responses after some filter and formatting.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        response_df (dict): Dataframe of colleciont of respones.\n",
    "        \"\"\"\n",
    "        json_data = {}\n",
    "        for key, response in data.items():\n",
    "            response_json = response.json()\n",
    "            json_data[key] = {\n",
    "                \"CREATEDATETIME\":  dt.datetime.today().strftime('%Y-%m-%d'), # IF DOES NOT EXIST: dt.datetime.today().strftime('%Y-%m-%d')\n",
    "                \"FIRST_NAME\": response_json[\"person\"].get(\"name\", \"\").get(\"givenName\", \"\"),\n",
    "                \"LAST_NAME\": response_json[\"person\"].get(\"name\", \"\").get(\"familyName\", \"\"),\n",
    "                \"EMAIL\": key,\n",
    "                \"COMPANY\": response_json[\"company\"].get(\"name\", \"\")\n",
    "                \"LAST_OUTREACH\":  dt.datetime.today().strftime('%Y-%m-%d'),\n",
    "                \"FIRST_OUTREACH\": dt.datetime.today().strftime('%Y-%m-%d'), # IF DOES NOT EXIST: dt.datetime.today().strftime('%Y-%m-%d')\n",
    "            }\n",
    "        response_df = pd.DataFrame.from_dict(json_data, orient=\"index\")\n",
    "        response_df.reset_index(drop=True, inplace=True)\n",
    "        return response_df\n",
    "\n",
    "\n",
    "    def clean_df(self, df, drop_columns, pattern, permuted_columns=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drops columns from frame. \n",
    "        Cleans up columns using regex pattern matching. \n",
    "        If permuted_columns is provided, will re-arrange dataframe columns accordingly.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        df (pd.DataFrame): Dataframe to process.\n",
    "        drop_columns ([any]): List of columns to drop.\n",
    "        pattern (str): Regex expression for column-renaming.\n",
    "        permuted_columns ([any]): Column re-arrangement list. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df (pd.DataFrame): DataFrame.\n",
    "        \"\"\"\n",
    "        df.drop(columns=drop_columns, inplace=True)\n",
    "        original_columns = df.columns.to_list()\n",
    "        new_columns = list(map(lambda x: re.sub(pattern, \"\", x), original_columns))\n",
    "        columns_dict = dict(zip(original_columns, new_columns))\n",
    "        df.rename(columns=columns_dict, inplace=True)\n",
    "        if permuted_columns != None:\n",
    "            df = df[permuted_columns]\n",
    "        return df\n",
    "\n",
    "\n",
    "    def update_dataframe_conditionally(\n",
    "        self,\n",
    "        new_df: pd.DataFrame, \n",
    "        original_df: pd.DataFrame,\n",
    "        merge_columns: list,\n",
    "        fixed_columns: list,\n",
    "        update_columns: list,\n",
    "        sort_by=None,\n",
    "        ascending=False,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Update using provided conditions as lists.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        new_df (pd.DataFrame): Dataframe with new data.\n",
    "        original_df (pd.DataFrame): Dataframe with original data.\n",
    "        merge_columns (['str']): Columns to merge data on. \n",
    "        fixed_columns (['str']): Columns to preserve data.\n",
    "        update_columns (['str']): Columns to update data.\n",
    "        sort_by (any): Column(s) to sort returning DataFrame. \n",
    "        ascending (bool): Direction to sort. Defaults to descending order.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        updated_df (pd.DataFrame): Returns updated DataFrame\n",
    "        \"\"\"\n",
    "        SUFFIXES = (\"_new\", \"_old\")\n",
    "        updated_df = None\n",
    "\n",
    "        # Reg ex pattern.\n",
    "        pattern = r\"|\".join(SUFFIXES)\n",
    "\n",
    "        # Double-check that update_columns does not conflict with merge columns.\n",
    "        update_columns = [col for col in update_columns if not col in merge_columns]\n",
    "\n",
    "        # Start flow.\n",
    "        original_columns = original_df.columns.to_list()\n",
    "        merged_df = new_df.merge(original_df, how=\"outer\", on=merge_columns, suffixes=SUFFIXES)\n",
    "        update_data = new_df.merge(original_df, how=\"inner\", on=merge_columns, suffixes=SUFFIXES)\n",
    "\n",
    "        # New data.\n",
    "        drop_columns = [col + SUFFIXES[1] for col in fixed_columns + update_columns]\n",
    "        new_data = merged_df[merged_df[drop_columns].isna().all(axis=1)]\n",
    "        new_data = clean_df(new_data, drop_columns, pattern, permuted_columns=original_columns)\n",
    "\n",
    "        # No-change data.\n",
    "        drop_columns = [col + SUFFIXES[0] for col in fixed_columns + update_columns]\n",
    "        no_change_data = merged_df[merged_df[drop_columns].isna().all(axis=1)]\n",
    "        no_change_data = clean_df(no_change_data, drop_columns, pattern, permuted_columns=original_columns)\n",
    "\n",
    "        # Update data.\n",
    "        drop_columns = [col + SUFFIXES[0] for col in fixed_columns] + [col + SUFFIXES[1] for col in update_columns]\n",
    "        update_data = self.clean_df(update_data, drop_columns, pattern, permuted_columns=original_columns)\n",
    "\n",
    "        updated_df = pd.concat([new_data, no_change_data, update_data])\n",
    "        if sort_by != None:\n",
    "            updated_df.sort_values(sort_by, ascending=ascending)\n",
    "\n",
    "        return updated_df\n",
    "\n",
    "\n",
    "    def db_contacts_updater(\n",
    "        self, \n",
    "        credentials_path: str, \n",
    "        clearbit_api_key: str,\n",
    "        db_identifier: str, \n",
    "        table: str,\n",
    "        recipients: list,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Updates a given database by an identifier. Usually some key. \n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        credentials_path (str): Path to credentials.\n",
    "        clearbit_api_key (str): Clearbit API key.\n",
    "        db_identifier (str): Key identifying location of database. \n",
    "        table (str): Table to write to.\n",
    "        recipients (list): List of recipients who were contacted.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (none)\n",
    "        \"\"\"\n",
    "        # NOTE: This is a good start for a general database updater.\n",
    "        sort_by = [\"CREATEDATETIME\"]\n",
    "\n",
    "        merge_columns, fixed_columns, update_columns, sort_by = self._load_config(credentials_path)\n",
    "\n",
    "        google = Google()\n",
    "        _, gsheets = google.google_connect(credentials_path=credentials_path)\n",
    "        sh = gsheets.open_by_key(db_identifier)\n",
    "        worksheets = sh.worksheets()\n",
    "        wks = sh.worksheet(\"title\", table)\n",
    "\n",
    "        original_df = wks.get_as_df()\n",
    "\n",
    "        recipient_data = {}\n",
    "        for recipient in recipients:\n",
    "            url = f\"https://person.clearbit.com/v2/combined/find?email=:{recipient}\"\n",
    "            clearbit_response = requests.get(url, auth=(clearbit_api_key, None))\n",
    "            recipient_data[recipient] = clearbit_response\n",
    "\n",
    "        new_data = self.responses_to_df(recipient_data)\n",
    "\n",
    "        updated_data = self.update_dataframe_conditionally(new_data, original_df, merge_columns, fixed_columns, update_columns, sort_by=sort_by, ascending=False,)\n",
    "\n",
    "        google.write_to_googlesheets(updated_data, db_identifier, gsheets, table, row_start=\"A1\")\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "credentials_path = r\"/Users/jaimemerizalde/Desktop/JOBS 2023/software/jmailer/secrets/db_secret.json\"\n",
    "\n",
    "# gkey\n",
    "db_identifier = \"1t1wGAQvZuwEWOOgcgtBaqbZoafG_ZCfTV5QGyMfYHTg\"\n",
    "\n",
    "table_identifier = \"contacts\"\n",
    "\n",
    "#filepath or list.\n",
    "recipients = [\n",
    "    \"marco.starger@getgarner.com\", \n",
    "    \"austin.lovell@getgarner.com\", \n",
    "    \"evelyn.siu@getgarner.com\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_configs = yaml.safe_load(open(DB_CONFIG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_configs\n",
    "\n",
    "# now parse them. \n",
    "\n",
    "# if you are going to have settings, make sure you HAVE to fetch these.\n",
    "merge_columns = db_configs[\"column_configs\"][\"merge_columns\"]\n",
    "fixed_columns = db_configs[\"column_configs\"][\"fixed_columns\"]\n",
    "update_columns = db_configs[\"column_configs\"][\"update_columns\"]\n",
    "sort_by = db_configs[\"column_configs\"].get(\"sort_by\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column_configs': {'merge_columns': ['FIRST_NAME',\n",
       "   'LAST_NAME',\n",
       "   'EMAIL',\n",
       "   'COMPANY'],\n",
       "  'fixed_columns': ['FIRST_OUTREACH', 'CREATEDATETIME'],\n",
       "  'update_columns': ['LAST_OUTREACH'],\n",
       "  'sort_by': 'CREATEDATETIME'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STart the db work flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# db connectivity\n",
    "# to be specified in an argparse config file for convenience\n",
    "\n",
    "# Google connectivity\n",
    "gg = Google()\n",
    "_, gsheets = gg.google_connect(credentials_path=credentials_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database fetcher\n",
    "sh = gsheets.open_by_key(db_identifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema fetcher\n",
    "worksheets = sh.worksheets()\n",
    "# titles = [wk.title for wk in worksheets]\n",
    "#wks_dict = dict(zip(titles, worksheets))\n",
    "#wks_dfs = dict(zip(titles, [wk.get_as_df() for wk in worksheets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table fetcher\n",
    "wks = sh.worksheet(\"title\", table_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completes the connection steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATEDATETIME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>LAST_OUTREACH</th>\n",
       "      <th>FIRST_OUTREACH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>Marco</td>\n",
       "      <td>Starger</td>\n",
       "      <td>marco.starger@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>09/08/2023</td>\n",
       "      <td>09/08/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/08/2023</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Lovell</td>\n",
       "      <td>austin.lovell@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>09/08/2023</td>\n",
       "      <td>09/08/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Siu</td>\n",
       "      <td>evelyn.siu@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/04/2023</td>\n",
       "      <td>KEVIN</td>\n",
       "      <td></td>\n",
       "      <td>kevin@getgarner.com</td>\n",
       "      <td>GARNER HEALTH</td>\n",
       "      <td>09/02/2923</td>\n",
       "      <td>09/02/2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/04/2023</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>BANYS</td>\n",
       "      <td>justinas.banys@getgarner.com</td>\n",
       "      <td>GARNER HEALTH</td>\n",
       "      <td>09/02/2923</td>\n",
       "      <td>09/02/2923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREATEDATETIME FIRST_NAME LAST_NAME                         EMAIL   \n",
       "0     2023-09-08      Marco   Starger   marco.starger@getgarner.com  \\\n",
       "1     09/08/2023     Austin    Lovell   austin.lovell@getgarner.com   \n",
       "2     2023-09-08     Evelyn       Siu      evelyn.siu@getgarner.com   \n",
       "3     09/04/2023      KEVIN                     kevin@getgarner.com   \n",
       "4     09/04/2023     JUSTIN     BANYS  justinas.banys@getgarner.com   \n",
       "\n",
       "         COMPANY LAST_OUTREACH FIRST_OUTREACH  \n",
       "0  Garner Health    09/08/2023     09/08/2023  \n",
       "1  Garner Health    09/08/2023     09/08/2023  \n",
       "2  Garner Health    2023-09-08     2023-09-08  \n",
       "3  GARNER HEALTH    09/02/2923     09/02/2923  \n",
       "4  GARNER HEALTH    09/02/2923     09/02/2923  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  table data  to dataframe\n",
    "wks.get_as_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next step is to....\n",
    "\n",
    "# collect recipient data using cla\n",
    "\n",
    "# basically, we should have a table-updateer \"script\" \n",
    "\n",
    "# this class or method (originally considered writing a script) is responsible for updating a table provided the data we need.\n",
    "# credentials as well. \n",
    "\n",
    "original_df = wks.get_as_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete me\n",
    "# save this data just in case bad connection\n",
    "# import pickle\n",
    "# original_df.to_pickle(\"/Users/jaimemerizalde/Desktop/tempdata.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we want next?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "participant data...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so given:\n",
    "recipients\n",
    "\n",
    "# give me one of these two \n",
    "config_path = \"/Users/jaimemerizalde/Desktop/JOBS 2023/software/jmailer/config.yaml\"\n",
    "clearbit_api_key = None \n",
    "\n",
    "if config_path != None:\n",
    "    config = yaml.safe_load(open(config_path))\n",
    "    credentials = config[\"credentials\"]\n",
    "    clearbit_api_key = credentials[\"clearbit\"][\"api_key\"]\n",
    "\n",
    "# take the config \n",
    "recipient_data = {}\n",
    "for recipient in recipients:\n",
    "    url = f\"https://person.clearbit.com/v2/combined/find?email=:{recipient}\"\n",
    "    # what the hell is giong on?\n",
    "\n",
    "    clearbit_response = requests.get(url, auth=(clearbit_api_key, None))\n",
    "    recipient_data[recipient] = clearbit_response\n",
    "\n",
    "# JSONIFY the data\n",
    "# Now put it together in a dictionary.\n",
    "recipient_push_data = {}\n",
    "for recipient, response in recipient_data.items():\n",
    "    response_json = response.json()\n",
    "    recipient_push_data[recipient] = {\n",
    "        \"CREATEDATETIME\":  dt.datetime.today().strftime('%Y-%m-%d'), # IF DOES NOT EXIST: dt.datetime.today().strftime('%Y-%m-%d')\n",
    "        \"FIRST_NAME\": response_json[\"person\"][\"name\"][\"givenName\"],\n",
    "        \"LAST_NAME\": response_json[\"person\"][\"name\"][\"familyName\"],\n",
    "        \"EMAIL\": recipient,\n",
    "        \"COMPANY\": response_json[\"company\"][\"name\"],\n",
    "        \"LAST_OUTREACH\":  dt.datetime.today().strftime('%Y-%m-%d'),\n",
    "        \"FIRST_OUTREACH\": dt.datetime.today().strftime('%Y-%m-%d'), # IF DOES NOT EXIST: dt.datetime.today().strftime('%Y-%m-%d')\n",
    "    }\n",
    "\n",
    "recipient_push_data = pd.DataFrame.from_dict(recipient_push_data, orient=\"index\")\n",
    "recipient_push_data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recipient_data[\"marco.starger@getgarner.com\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATEDATETIME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>LAST_OUTREACH</th>\n",
       "      <th>FIRST_OUTREACH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Marco</td>\n",
       "      <td>Starger</td>\n",
       "      <td>marco.starger@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>2023-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Lovell</td>\n",
       "      <td>austin.lovell@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>2023-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Siu</td>\n",
       "      <td>evelyn.siu@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>2023-09-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREATEDATETIME FIRST_NAME LAST_NAME                        EMAIL   \n",
       "0     2023-09-09      Marco   Starger  marco.starger@getgarner.com  \\\n",
       "1     2023-09-09     Austin    Lovell  austin.lovell@getgarner.com   \n",
       "2     2023-09-09     Evelyn       Siu     evelyn.siu@getgarner.com   \n",
       "\n",
       "         COMPANY LAST_OUTREACH FIRST_OUTREACH  \n",
       "0  Garner Health    2023-09-09     2023-09-09  \n",
       "1  Garner Health    2023-09-09     2023-09-09  \n",
       "2  Garner Health    2023-09-09     2023-09-09  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipient_push_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# complete data fetching flows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the data fetching work, you can do the data blending work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATEDATETIME</th>\n",
       "      <th>FIRST_NAME</th>\n",
       "      <th>LAST_NAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>LAST_OUTREACH</th>\n",
       "      <th>FIRST_OUTREACH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>Marco</td>\n",
       "      <td>Starger</td>\n",
       "      <td>marco.starger@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>09/08/2023</td>\n",
       "      <td>09/08/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/08/2023</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Lovell</td>\n",
       "      <td>austin.lovell@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>09/08/2023</td>\n",
       "      <td>09/08/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>Siu</td>\n",
       "      <td>evelyn.siu@getgarner.com</td>\n",
       "      <td>Garner Health</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/04/2023</td>\n",
       "      <td>KEVIN</td>\n",
       "      <td></td>\n",
       "      <td>kevin@getgarner.com</td>\n",
       "      <td>GARNER HEALTH</td>\n",
       "      <td>09/02/2923</td>\n",
       "      <td>09/02/2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/04/2023</td>\n",
       "      <td>JUSTIN</td>\n",
       "      <td>BANYS</td>\n",
       "      <td>justinas.banys@getgarner.com</td>\n",
       "      <td>GARNER HEALTH</td>\n",
       "      <td>09/02/2923</td>\n",
       "      <td>09/02/2923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CREATEDATETIME FIRST_NAME LAST_NAME                         EMAIL   \n",
       "0     2023-09-08      Marco   Starger   marco.starger@getgarner.com  \\\n",
       "1     09/08/2023     Austin    Lovell   austin.lovell@getgarner.com   \n",
       "2     2023-09-08     Evelyn       Siu      evelyn.siu@getgarner.com   \n",
       "3     09/04/2023      KEVIN                     kevin@getgarner.com   \n",
       "4     09/04/2023     JUSTIN     BANYS  justinas.banys@getgarner.com   \n",
       "\n",
       "         COMPANY LAST_OUTREACH FIRST_OUTREACH  \n",
       "0  Garner Health    09/08/2023     09/08/2023  \n",
       "1  Garner Health    09/08/2023     09/08/2023  \n",
       "2  Garner Health    2023-09-08     2023-09-08  \n",
       "3  GARNER HEALTH    09/02/2923     09/02/2923  \n",
       "4  GARNER HEALTH    09/02/2923     09/02/2923  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/j0_twvc12kb14hzn7ps4qy340000gn/T/ipykernel_28703/1252541605.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=drop_columns, inplace=True)\n",
      "/var/folders/v3/j0_twvc12kb14hzn7ps4qy340000gn/T/ipykernel_28703/1252541605.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=columns_dict, inplace=True)\n",
      "/var/folders/v3/j0_twvc12kb14hzn7ps4qy340000gn/T/ipykernel_28703/1252541605.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=drop_columns, inplace=True)\n",
      "/var/folders/v3/j0_twvc12kb14hzn7ps4qy340000gn/T/ipykernel_28703/1252541605.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=columns_dict, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# merged_columns = []\n",
    "\n",
    "df_update = update_dataframe_conditionally(\n",
    "    recipient_push_data,\n",
    "    original_df, \n",
    "    merge_columns,\n",
    "    fixed_columns,\n",
    "    update_columns,\n",
    "    sort_by=\"CREATEDATETIME\",\n",
    "    ascending=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'D SAY that if you have a config file, then you can't really have it mess up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to push the data out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed data to gsheet with key:1t1wGAQvZuwEWOOgcgtBaqbZoafG_ZCfTV5QGyMfYHTg Timestamp: 15:07:46 - 2023-09-09\n"
     ]
    }
   ],
   "source": [
    "gg.write_to_googlesheets(df_update, db_identifier, gsheets, table_identifier, row_start=\"A1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventually you'll end up down here and putting together all the tools still in sketch mode  from above. \n",
    "\n",
    "# nere you are wrapping this up.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture: \n",
    "\n",
    "Imports\n",
    "Constants\n",
    "\n",
    "Classes / methods.\n",
    "\n",
    "You have argments / unfixed inputs.  \n",
    "\n",
    "You need to have a way to receive these recipients.. If you make this importable, you could just have them be \"givens\"\n",
    "\n",
    "Honestly, you could probably just start writing all of this stuff now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay let's test this damn class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "credentials_path = r\"/Users/jaimemerizalde/Desktop/JOBS 2023/software/jmailer/secrets/db_secret.json\"\n",
    "\n",
    "# gkey\n",
    "db_identifier = \"1t1wGAQvZuwEWOOgcgtBaqbZoafG_ZCfTV5QGyMfYHTg\"\n",
    "\n",
    "table_identifier = \"contacts\"\n",
    "\n",
    "# #filepath or list.\n",
    "# recipients = [\n",
    "#     \"marco.starger@getgarner.com\", \n",
    "#     \"austin.lovell@getgarner.com\", \n",
    "#     \"evelyn.siu@getgarner.com\",\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DB_handler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db_guy \u001b[39m=\u001b[39m DB_handler()\n\u001b[1;32m      2\u001b[0m \u001b[39m# db_guy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m         \u001b[39m# new_data = self.response_to_df(recipient_data)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m new_data \u001b[39m=\u001b[39m db_guy\u001b[39m.\u001b[39mdb_contacts_updater(\n\u001b[1;32m      7\u001b[0m     credentials_path,\n\u001b[1;32m      8\u001b[0m     clearbit_api_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     recipients\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DB_handler' is not defined"
     ]
    }
   ],
   "source": [
    "db_guy = DB_handler()\n",
    "# db_guy\n",
    "\n",
    "\n",
    "        # new_data = self.response_to_df(recipient_data)\n",
    "new_data = db_guy.db_contacts_updater(\n",
    "    credentials_path,\n",
    "    clearbit_api_key,\n",
    "    db_identifier,\n",
    "    table_identifier,\n",
    "    recipients\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "cb_key_path = \"/Users/jaimemerizalde/Desktop/JOBS 2023/software/jmailer/config.yaml\"\n",
    "# /Users/jaimemerizalde/Desktop/JOBS 2023/software/jmailer\n",
    "credentials_path = \"/Users/jaimemerizalde/Desktop/JOBS 2023/software/jmailer/secrets/\"\n",
    "credentials = yaml.safe_load(open(cb_key_path))\n",
    "clearbit_api_key = credentials[\"credentials\"][\"clearbit\"][\"api_key\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on importing this thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipients = [\n",
    "    \"marco.starger@getgarner.com\", \n",
    "    \"austin.lovell@getgarner.com\", \n",
    "    \"evelyn.siu@getgarner.com\",\n",
    "    \"jaime.meriz13@gmail.com\",\n",
    "]\n",
    "db_identifier = \"1t1wGAQvZuwEWOOgcgtBaqbZoafG_ZCfTV5QGyMfYHTg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No response recorded for jaime.meriz13@gmail.com. 'NoneType' object has no attribute 'get' Timestamp: 23:58:58 - 2023-09-10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db_handler\u001b[39m.\u001b[39;49mDB_handler()\u001b[39m.\u001b[39;49mdb_contacts_updater(\n\u001b[1;32m      2\u001b[0m     credentials_path,\n\u001b[1;32m      3\u001b[0m     clearbit_api_key,\n\u001b[1;32m      4\u001b[0m     db_identifier,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcontacts\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     recipients,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[39m# It worked!\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# now let's see if it worked correctly.  \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/JOBS 2023/software/jmailer/jmailer/db_handler.py:378\u001b[0m, in \u001b[0;36mDB_handler.db_contacts_updater\u001b[0;34m(self, credentials_path, clearbit_api_key, db_identifier, table, recipients)\u001b[0m\n\u001b[1;32m    374\u001b[0m     recipient_data[recipient] \u001b[39m=\u001b[39m clearbit_response\n\u001b[1;32m    376\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponses_to_df(recipient_data)\n\u001b[0;32m--> 378\u001b[0m \u001b[39mif\u001b[39;00m new_data \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     updated_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_dataframe_conditionally(new_data, original_df, merge_columns, fixed_columns, update_columns, sort_by\u001b[39m=\u001b[39msort_by, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,)\n\u001b[1;32m    380\u001b[0m     google\u001b[39m.\u001b[39mwrite_to_googlesheets(updated_data, db_identifier, gsheets, table, row_start\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA1\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/petdesk/lib/python3.11/site-packages/pandas/core/generic.py:1466\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1465\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1466\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1467\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1468\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1469\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "new_data = db_handler.DB_handler().db_contacts_updater(\n",
    "    credentials_path,\n",
    "    clearbit_api_key,\n",
    "    db_identifier,\n",
    "    \"contacts\",\n",
    "    recipients,\n",
    ")\n",
    "\n",
    "# It worked!\n",
    "# now let's see if it worked correctly.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_data' is not defined"
     ]
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petdesk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
